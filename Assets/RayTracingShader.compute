// Each #kernel tells which function to compile; you can have many kernels
#pragma kernel CSMain

// Create a RenderTexture with enableRandomWrite flag and set it with cs.SetTexture
RWTexture2D<float4> Result;

//Define the matrices we pass to this shader.
float4x4 _CameraToWorld;
float4x4 _CameraInverseProjection;

Texture2D<float4> _SkyboxTexture;
SamplerState sampler_SkyboxTexture;

static const float PI = 3.14159265f;

struct Ray
{
    float3 origin;
    float3 direction;
};

Ray CreateRay(float3 origin, float3 direction)
{
    Ray ray;
    ray.origin = origin;
    ray.direction = direction;
    return ray;
}

//Get the camera origin in world space and the direction of the ray in world space. for each pixel.
Ray CreateCameraRay(float2 uv)
{
    // Calculate the camera position in world space by multiplying the cameraToWorld matrix by a point. 
    // The point is (0.0f, 0.0f, 0.0f, 1.0f) which represents the camera's position in its own local space.
    float3 origin = mul(_CameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).xyz;
    
    // Convert a 2D point from normalized device coordinates (clip space) to a 3D direction vector in camera space.
    float3 direction = mul(_CameraInverseProjection, float4(uv, 0.0f, 1.0f)).xyz;
    
    // Transform the direction from camera to world space and normalize
    direction = mul(_CameraToWorld, float4(direction, 0.0f)).xyz;
    direction = normalize(direction);
    
    return CreateRay(origin, direction);
}

// Define the number of threads per thread group, which determines how many threads will run in parallel within a single group.
// Here, we have 64 (8 in the x dimension times 8 in the y dimension) threads per group. 
// The total number of thread groups is defined in the accompanying C# dispatch call.
[numthreads(8, 8, 1)]
void CSMain(uint3 id : SV_DispatchThreadID) // The main compute shader function.
{
    // The dimensions of the target RenderTexture are retrieved. 
    // These dimensions dictate how many unique UV coordinates we will generate, one for each thread.
    uint width, height;
    Result.GetDimensions(width, height);
    
    // Calculate the UV coordinates for the current thread.
    // UV coordinates are normalized from [0, 1], but we shift them to [-1, 1] to map to our screen space.
    float2 uv = float2((id.xy + float2(0.5f, 0.5f)) / float2(width, height) * 2.0f - 1.0f);
    
    // Generate a ray from the camera for the current UV coordinates.
    Ray ray = CreateCameraRay(uv);
    
    // Instead of writing a solid color, we will now sample from a texture.
    // We convert the ray's direction into spherical coordinates (theta, phi) for texture sampling.
    // Theta is the angle from the top view vector (Y-axis), and Phi is the angle from the Z-axis in the XZ plane.
    // We sample from the skybox texture using these spherical coordinates.
    // The SampleLevel function samples the texture at a specific mipmap level, in this case, the top level (0).
    float theta = acos(ray.direction.y) / -PI;
    float phi = atan2(ray.direction.x, -ray.direction.z) / -PI * 0.5f;
    Result[id.xy] = _SkyboxTexture.SampleLevel(sampler_SkyboxTexture, float2(phi, theta), 0);
}
